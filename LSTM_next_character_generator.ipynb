{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Next Character Generator: LSTM"
      ],
      "metadata": {
        "id": "TnXRlFXb1t5h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Ec3I8_a71bFf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a unique character dictionary"
      ],
      "metadata": {
        "id": "McFa1pjL1-zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = ['\\n', '\\r', ' ', '!', '\"', \"'\", '(', ')', '‘', '’', '*', '”', '“', ',', '—', '-', '.', ':', ';', '?', '[', ']',\n",
        "'_', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p',\n",
        "'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xbb', '\\xbf', '\\xef']"
      ],
      "metadata": {
        "id": "Nq5_FCzK13SO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "VYGLXXCQ13oB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Alice’s Adventures in Wonderland.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "bDmCRHco1sQg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert into lower case\n",
        "text = text.lower()"
      ],
      "metadata": {
        "id": "3TTYmLi-2dSA"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the data\n",
        "n_chars = len(text)\n",
        "n_vocab = len(dictionary)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8JOq9wb2lnn",
        "outputId": "709a2ce8-b737-48fd-f495-86651a253b0b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  144581\n",
            "Total Vocab:  62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique characters and mapping\n",
        "chars = sorted(set(text))  # Collect unique characters\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "o_zQ4ThA5Bhs"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(char_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6YnIyUp8VmQ",
        "outputId": "145d3995-7d6b-4737-c332-0b39e96c1074"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an Input Output Dataset"
      ],
      "metadata": {
        "id": "jkpPn0JY4ZkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Define sequence length (window size)\n",
        "SEQ_LENGTH = 40  # Adjust based on your dataset\n",
        "\n",
        "# Create input-output pairs\n",
        "input_sequences = []\n",
        "target_chars = []\n",
        "\n",
        "for i in range(len(text) - SEQ_LENGTH):\n",
        "    input_sequences.append([char_to_idx[c] for c in text[i:i+SEQ_LENGTH]])\n",
        "    target_chars.append(char_to_idx[text[i+SEQ_LENGTH]])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(input_sequences)\n",
        "y = np.array(target_chars)\n",
        "\n",
        "# Save processed data to avoid re-processing\n",
        "with open(\"processed_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump((X, y, char_to_idx, idx_to_char), f)\n",
        "\n",
        "print(\"Data processing complete. Saved as 'processed_data.pkl'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYcaSdAB2wUI",
        "outputId": "f608dd7e-9521-4877-8b46-d8e156302681"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data processing complete. Saved as 'processed_data.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QG4F_KPz51DJ",
        "outputId": "45f2ded1-0c44-47e1-c8f9-d7f3cdd545ee"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alice’s adventures in wonderland\\n\\nby lewis carroll\\n\\nthe millennium fulcrum edition 3.0\\n\\ncontents\\n\\n c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the dataset"
      ],
      "metadata": {
        "id": "JZACmkOY8-ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the processed data\n",
        "with open(\"processed_data.pkl\", \"rb\") as f:\n",
        "    X, y, char_to_idx, idx_to_char = pickle.load(f)"
      ],
      "metadata": {
        "id": "Ws4EM4ff52M2"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes of loaded arrays\n",
        "print(\"Input shape (X):\", X.shape)\n",
        "print(\"Output shape (y):\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rHXizVw9DoY",
        "outputId": "5a48d628-1fcb-43d4-9087-06899541c80d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape (X): (144541, 40)\n",
            "Output shape (y): (144541,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert these into PyTorch tensors\n",
        "X = torch.from_numpy(X).type(torch.float)\n",
        "y = torch.from_numpy(y)"
      ],
      "metadata": {
        "id": "Mtt95jtM9GEJ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = X.shape[0]\n",
        "n_patterns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShdpGxff9efO",
        "outputId": "da081027-ecb2-46a5-98dd-3024f597c896"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144541"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM layer is going to be used in the model, thus the input tensor should be of dimension (sample, time steps, features)."
      ],
      "metadata": {
        "id": "f_Mk-xyf9p0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.reshape(n_patterns, SEQ_LENGTH, 1)"
      ],
      "metadata": {
        "id": "em8ixayT9fhj"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15P_GNjw-Clt",
        "outputId": "76aec9ef-c728-4bfe-f093-8faea46da2e9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([144541, 40, 1]) torch.Size([144541])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create LSTM Model"
      ],
      "metadata": {
        "id": "Ka8R5Aal-blC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "RBETGCV1-H7j"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzqO6e0-E2RL",
        "outputId": "703b6c56-bed0-4bf7-a35e-ce3fa33a65a0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCharModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(LSTMCharModel, self).__init__()\n",
        "      self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True)\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "      self.linear = nn.Linear(256, n_vocab)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x, _ = self.lstm(x)\n",
        "      # take only the last output\n",
        "      x = x[:, -1, :]\n",
        "      # produce output\n",
        "      x = self.linear(self.dropout(x))\n",
        "      return x"
      ],
      "metadata": {
        "id": "evqzSpMu-j2-"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Parameters\n",
        "n_epochs = 40\n",
        "batch_size = 128\n",
        "model = LSTMCharModel()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "loader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "v3aHIWPWG3sE"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  for X_batch, y_batch in loader:\n",
        "\n",
        "    # Data to GPU\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "\n",
        "    output = model(X_batch)  # Forward pass\n",
        "\n",
        "    loss = loss_fn(output, y_batch) # Compute loss\n",
        "    loss.backward()  # Backpropagation\n",
        "\n",
        "    optimizer.step()  # Update weights\n",
        "\n",
        "  # if epoch % 100 == 0:\n",
        "  print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmeRKIu_FO4s",
        "outputId": "44156922-71aa-4054-e149-f2208e8343bb"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Loss: 61.6631\n",
            "Epoch [2/40], Loss: 62.6703\n",
            "Epoch [3/40], Loss: 48.3693\n",
            "Epoch [4/40], Loss: 68.8345\n",
            "Epoch [5/40], Loss: 55.2626\n",
            "Epoch [6/40], Loss: 59.4498\n",
            "Epoch [7/40], Loss: 59.6884\n",
            "Epoch [8/40], Loss: 50.5259\n",
            "Epoch [9/40], Loss: 43.8814\n",
            "Epoch [10/40], Loss: 55.5586\n",
            "Epoch [11/40], Loss: 61.1853\n",
            "Epoch [12/40], Loss: 57.0465\n",
            "Epoch [13/40], Loss: 46.3952\n",
            "Epoch [14/40], Loss: 51.5665\n",
            "Epoch [15/40], Loss: 49.9568\n",
            "Epoch [16/40], Loss: 63.7949\n",
            "Epoch [17/40], Loss: 46.7754\n",
            "Epoch [18/40], Loss: 45.6253\n",
            "Epoch [19/40], Loss: 63.5476\n",
            "Epoch [20/40], Loss: 53.0863\n",
            "Epoch [21/40], Loss: 38.5105\n",
            "Epoch [22/40], Loss: 45.8743\n",
            "Epoch [23/40], Loss: 58.8801\n",
            "Epoch [24/40], Loss: 63.0137\n",
            "Epoch [25/40], Loss: 55.3525\n",
            "Epoch [26/40], Loss: 48.4465\n",
            "Epoch [27/40], Loss: 39.4393\n",
            "Epoch [28/40], Loss: 46.2169\n",
            "Epoch [29/40], Loss: 42.3917\n",
            "Epoch [30/40], Loss: 40.3730\n",
            "Epoch [31/40], Loss: 43.9227\n",
            "Epoch [32/40], Loss: 34.2238\n",
            "Epoch [33/40], Loss: 35.7325\n",
            "Epoch [34/40], Loss: 33.8011\n",
            "Epoch [35/40], Loss: 54.0655\n",
            "Epoch [36/40], Loss: 40.5408\n",
            "Epoch [37/40], Loss: 42.8768\n",
            "Epoch [38/40], Loss: 48.2189\n",
            "Epoch [39/40], Loss: 58.3248\n",
            "Epoch [40/40], Loss: 46.8894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the next character"
      ],
      "metadata": {
        "id": "drOL6KaEIwlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 1\n",
        "\n",
        "def predict_next_word(text):\n",
        "\n",
        "  #  lower case\n",
        "  text = next_char_text.lower()\n",
        "\n",
        "  # tokenize the text\n",
        "  tokenize = [char_to_idx[c] for c in text]\n",
        "\n",
        "  # convert into tensor\n",
        "  input_tensor = torch.tensor(tokenize).type(torch.float).reshape(1, -1, 1)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():  # No gradient computation needed\n",
        "\n",
        "        # Shift to GPU\n",
        "        input_tensor = input_tensor.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_tensor)\n",
        "\n",
        "        # Get top-k predictions\n",
        "        predicted_indices = torch.topk(output, top_k, dim=1).indices.squeeze(0)\n",
        "\n",
        "        # get char from indicea\n",
        "        predicted_chars = [idx_to_char[idx.item()] for idx in predicted_indices]\n",
        "\n",
        "        return predicted_chars\n"
      ],
      "metadata": {
        "id": "TiGPx4k3JYPj"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_char_text = \"I wonder what L\"\n",
        "\n",
        "predicted_output = predict_next_word(next_char_text)\n",
        "print(\"Input:\", next_char_text)\n",
        "print(\"Output\", next_char_text + predicted_output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_BUUmpfLSrW",
        "outputId": "7ece03d6-7acb-475b-fbc0-b18d0d6269cc"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 15, 1])\n",
            "Input: I wonder what L\n",
            "Output I wonder what Lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_char_text = \"Alice was not a bit hurt, and\"\n",
        "\n",
        "for _ in range(50):\n",
        "  predicted_output = predict_next_word(next_char_text)\n",
        "  print(f\"{next_char_text + predicted_output[0]}\")\n",
        "  next_char_text += predicted_output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATGfrYz1L_T-",
        "outputId": "8f6da5ab-3a1a-4ed5-c3c9-c987339c405d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice was not a bit hurt, and \n",
            "Alice was not a bit hurt, and t\n",
            "Alice was not a bit hurt, and th\n",
            "Alice was not a bit hurt, and the\n",
            "Alice was not a bit hurt, and the \n",
            "Alice was not a bit hurt, and the m\n",
            "Alice was not a bit hurt, and the mi\n",
            "Alice was not a bit hurt, and the mit\n",
            "Alice was not a bit hurt, and the mitt\n",
            "Alice was not a bit hurt, and the mittl\n",
            "Alice was not a bit hurt, and the mittle\n",
            "Alice was not a bit hurt, and the mittle \n",
            "Alice was not a bit hurt, and the mittle g\n",
            "Alice was not a bit hurt, and the mittle go\n",
            "Alice was not a bit hurt, and the mittle gor\n",
            "Alice was not a bit hurt, and the mittle gorr\n",
            "Alice was not a bit hurt, and the mittle gorre\n",
            "Alice was not a bit hurt, and the mittle gorre \n",
            "Alice was not a bit hurt, and the mittle gorre o\n",
            "Alice was not a bit hurt, and the mittle gorre of\n",
            "Alice was not a bit hurt, and the mittle gorre of \n",
            "Alice was not a bit hurt, and the mittle gorre of t\n",
            "Alice was not a bit hurt, and the mittle gorre of th\n",
            "Alice was not a bit hurt, and the mittle gorre of the\n",
            "Alice was not a bit hurt, and the mittle gorre of the \n",
            "Alice was not a bit hurt, and the mittle gorre of the m\n",
            "Alice was not a bit hurt, and the mittle gorre of the ma\n",
            "Alice was not a bit hurt, and the mittle gorre of the mar\n",
            "Alice was not a bit hurt, and the mittle gorre of the marc\n",
            "Alice was not a bit hurt, and the mittle gorre of the march\n",
            "Alice was not a bit hurt, and the mittle gorre of the march \n",
            "Alice was not a bit hurt, and the mittle gorre of the march h\n",
            "Alice was not a bit hurt, and the mittle gorre of the march ha\n",
            "Alice was not a bit hurt, and the mittle gorre of the march har\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare \n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare w\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare wa\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was \n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was s\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was se\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was ser\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was serl\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was serli\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was serlin\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was serlint\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was serlint \n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was serlint i\n",
            "Alice was not a bit hurt, and the mittle gorre of the march hare was serlint in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AbbasKothari1552/Next-Word-Generator.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80V4H7jcO1dR",
        "outputId": "edcd1447-06b8-4f22-8ca3-5e814c104932"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Next-Word-Generator'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv processed_data.pkl Next-Word-Generator/"
      ],
      "metadata": {
        "id": "EOYV5np1TW3e"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/Alice’s Adventures in Wonderland.txt\" Next-Word-Generator/\n"
      ],
      "metadata": {
        "id": "85v-KkSRTtkq"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Next-Word-Generator\n",
        "!git config --global user.email \"ask50405808@gmail.com.com\"\n",
        "!git config --global user.name \"AbbasKothari1552\"\n",
        "\n",
        "!git add .\n",
        "!git commit -m \"Added processed data and Text data\"\n",
        "!git push origin main  # Change `main` to the correct branch if needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8d7aXLnT1gC",
        "outputId": "ce44f26e-d054-4509-9197-6eabb9714b4a"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Next-Word-Generator'\n",
            "/content/Next-Word-Generator\n",
            "On branch main\n",
            "Your branch is based on 'origin/main', but the upstream is gone.\n",
            "  (use \"git branch --unset-upstream\" to fixup)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YUoSV3pNUKUm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}